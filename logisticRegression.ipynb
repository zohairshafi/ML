{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros) [ 0.69314718]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.203498\n",
      "         Iterations: 51\n",
      "         Function evaluations: 119\n",
      "         Gradient evaluations: 119\n",
      "[-25.12866083   0.20597036   0.20120723]\n",
      "[ 0.77601973]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from math import exp, log\n",
    "import scipy.optimize as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "data = np.loadtxt('/Users/Zohair/Library/Mobile Documents/com~apple~CloudDocs/Education/Machine Learning/machine-learning-ex2/ex2/ex2data1.txt', delimiter = \",\")\n",
    "\n",
    "# Sigmoid Function\n",
    "\n",
    "def sigmoid (x):\n",
    "    \n",
    "    result = []\n",
    "    size = np.shape(x)\n",
    "    \n",
    "    try:\n",
    "        for i in x.flat:\n",
    "            result.append((1 / (1 + exp(-i))))\n",
    "        return np.reshape(result, size)\n",
    "    except:\n",
    "        return (1 / (1 + exp(-x)))\n",
    "\n",
    "\n",
    "# Cost Function and Gradient\n",
    "\n",
    "def computeCost(X, y, theta, lmbda):\n",
    "\n",
    "    (m, n) = np.shape(X)\n",
    "    grad = np.zeros(np.shape(theta))\n",
    "    # errorVector = np.zeros((n, 1))\n",
    "    \n",
    "    prediction = np.dot(X, theta)\n",
    "    hypothesis = sigmoid(prediction)\n",
    "    \n",
    "    J = (1/m) * (- (np.dot(np.transpose(y), np.log(hypothesis))) - np.dot(np.transpose(1 - y), np.log(1 - hypothesis) ))\n",
    "    errorVector = hypothesis - y\n",
    "    grad = (1/m) * np.dot(np.transpose(X), errorVector)\n",
    "    \n",
    "    theta[1] = 0\n",
    "    regTerm = (lmbda/2 * m) * np.sum(np.square(theta))\n",
    "    regTermGrad = (lmbda/m) * theta\n",
    "\n",
    "    return J\n",
    "\n",
    "def computeGradient(X, y, theta, lmbda):\n",
    "    \n",
    "    (m, n) = np.shape(X)\n",
    "\n",
    "    prediction = np.dot(X, theta)\n",
    "    hypothesis = sigmoid(prediction)\n",
    "    errorVector = hypothesis - y\n",
    "    grad = (1/m) * np.dot(np.transpose(X), errorVector)\n",
    "    theta[1] = 0\n",
    "    regTermGrad = (lmbda/m) * theta\n",
    "    return grad\n",
    "\n",
    "def h(theta, X): #Logistic hypothesis function\n",
    "    return expit(np.dot(X, theta))\n",
    "\n",
    "# def computeCost(theta, X, y, lmbda = 0.): \n",
    "    \n",
    "#     term1 = np.dot(-np.array(y).T,np.log(h(theta, X)))\n",
    "#     term2 = np.dot((1-np.array(y)).T,np.log(1-h(theta, X)))\n",
    "#     regterm = (lmbda/2) * np.sum(np.dot(theta[1:].T,theta[1:])) #Skip theta0\n",
    "#     return float( (1./m) * ( np.sum(term1 - term2) + regterm ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "(m, n) = np.shape(data)\n",
    "\n",
    "# Add Column Of Ones\n",
    "temp = np.ones((m, 1)) \n",
    "data = np.hstack((temp, data))\n",
    "\n",
    "(m, n) = np.shape(data)\n",
    "\n",
    "# Initialise Theta\n",
    "initialTheta = np.zeros((n - 1, 1))\n",
    "\n",
    "# Get X and y from data\n",
    "(X, y) = np.hsplit(data, (n - 1,))\n",
    "y = y.flatten()\n",
    "\n",
    "# Initial Cost And Gradient\n",
    "cost = computeCost(X, y, initialTheta, 0)\n",
    "grad = computeGradient(X, y, initialTheta, 0)\n",
    "\n",
    "print (\"Cost at initial theta (zeros)\", cost)\n",
    "# print (\"Gradient at initial theta (zeros):\")\n",
    "# print (grad)\n",
    "\n",
    "def testFunction(theta):\n",
    "     return computeCost(X, y, theta, 0)\n",
    "\n",
    "def testFunctionTwo(theta):\n",
    "    return computeGradient(X, y, theta, 0)\n",
    "\n",
    "# Minimise Cost\n",
    "\n",
    "thetaFinal = sp.fmin_cg(testFunction, x0=initialTheta, fprime=testFunctionTwo)\n",
    "print(thetaFinal)\n",
    "\n",
    "testCase = np.array([[1, 45, 85]])\n",
    "prob = sigmoid (np.dot(testCase, thetaFinal))\n",
    "print(prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
