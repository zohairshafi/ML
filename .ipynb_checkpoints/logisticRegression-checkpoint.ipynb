{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from math import exp, log\n",
    "import scipy.optimize as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Data\n",
    "\n",
    "def plotData():\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(pos[:,1],pos[:,2],'k+',label='Admitted')\n",
    "    plt.plot(neg[:,1],neg[:,2],'yo',label='Not admitted')\n",
    "    plt.xlabel('Exam 1 score')\n",
    "    plt.ylabel('Exam 2 score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "\n",
    "# Sigmoid Function\n",
    "\n",
    "def sigmoid (x):\n",
    "    \n",
    "    result = []\n",
    "    size = np.shape(x)\n",
    "    \n",
    "    try:\n",
    "        for i in x.flat:\n",
    "            result.append((1 / (1 + exp(-i))))\n",
    "        return np.reshape(result, size)\n",
    "    except:\n",
    "        return (1 / (1 + exp(-x)))\n",
    "\n",
    "\n",
    "# Cost Function and Gradient\n",
    "\n",
    "def computeCost(theta, X, y, lmbda):\n",
    "\n",
    "    (m, n) = np.shape(X)\n",
    "    grad = np.zeros(np.shape(theta))\n",
    "    # errorVector = np.zeros((n, 1))\n",
    "    \n",
    "    prediction = np.dot(X, theta)\n",
    "    hypothesis = sigmoid(prediction)\n",
    "    \n",
    "    J = (1/m) * (- (np.dot(np.transpose(y), np.log(hypothesis))) - np.dot(np.transpose(1 - y), np.log(1 - hypothesis) ))\n",
    "    errorVector = hypothesis - y\n",
    "    grad = (1/m) * np.dot(np.transpose(X), errorVector)\n",
    "    \n",
    "    theta[1] = 0\n",
    "    regTerm = (lmbda/2 * m) * np.sum(np.square(theta))\n",
    "    regTermGrad = (lmbda/m) * theta\n",
    "\n",
    "    return J + regTerm\n",
    "\n",
    "def computeGradient(X, y, theta, lmbda):\n",
    "    \n",
    "    (m, n) = np.shape(X)\n",
    "\n",
    "    prediction = np.dot(X, theta)\n",
    "    hypothesis = sigmoid(prediction)\n",
    "    errorVector = hypothesis - y\n",
    "    grad = (1/m) * np.dot(np.transpose(X), errorVector)\n",
    "    theta[1] = 0\n",
    "    regTermGrad = (lmbda/m) * theta\n",
    "    return grad + regTermGrad\n",
    "\n",
    "def mapFeature( x1col, x2col ):\n",
    "    \"\"\" \n",
    "    Function that takes in a column of n- x1's, a column of n- x2s, and builds\n",
    "    a n- x 28-dim matrix of featuers as described in the homework assignment\n",
    "    \"\"\"\n",
    "    degrees = 6\n",
    "    out = np.ones( (x1col.shape[0], 1) )\n",
    "\n",
    "    for i in range(1, degrees+1):\n",
    "        for j in range(0, i+1):\n",
    "            term1 = x1col ** (i-j)\n",
    "            term2 = x2col ** (j)\n",
    "            term  = (term1 * term2).reshape( term1.shape[0], 1 ) \n",
    "            out   = np.hstack(( out, term ))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros) [ 0.69314718]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.203498\n",
      "         Iterations: 51\n",
      "         Function evaluations: 119\n",
      "         Gradient evaluations: 119\n",
      "[-25.12866083   0.20597036   0.20120723]\n",
      "[ 0.77601973]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zohair/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:45: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "# Ex2Data1\n",
    "\n",
    "data = np.loadtxt('/Users/Zohair/Library/Mobile Documents/com~apple~CloudDocs/Education/Machine Learning/machine-learning-ex2/ex2/ex2data1.txt', delimiter = \",\")\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "(m, n) = np.shape(data)\n",
    "\n",
    "# Add Column Of Ones\n",
    "temp = np.ones((m, 1)) \n",
    "data = np.hstack((temp, data))\n",
    "\n",
    "(m, n) = np.shape(data)\n",
    "\n",
    "# Get X and y from data\n",
    "(X, y) = np.hsplit(data, (n - 1,))\n",
    "y = y.flatten()\n",
    "\n",
    "\n",
    "#Divide the sample into two: ones with positive classification, one with null classification\n",
    "pos = np.array([X[i] for i in range(np.shape(X)[0]) if y[i] == 1])\n",
    "neg = np.array([X[i] for i in range(np.shape(X)[0]) if y[i] == 0])\n",
    "\n",
    "# Plot Data\n",
    "# plotData()\n",
    "\n",
    "# Initialise Theta\n",
    "initialTheta = np.zeros((n - 1, 1))\n",
    "\n",
    "# Paramaters\n",
    "\n",
    "lmbda = 0\n",
    "\n",
    "# Initial Cost And Gradient\n",
    "cost = computeCost(initialTheta, X, y, lmbda)\n",
    "grad = computeGradient(X, y, initialTheta, lmbda)\n",
    "\n",
    "print (\"Cost at initial theta (zeros)\", cost)\n",
    "# print (\"Gradient at initial theta (zeros):\")\n",
    "# print (grad)\n",
    "\n",
    "def testFunction(theta):\n",
    "     return computeCost(theta, X, y, lmbda)\n",
    "\n",
    "def testFunctionTwo(theta):\n",
    "    return computeGradient(X, y, theta, lmbda)\n",
    "\n",
    "# Minimise Cost\n",
    "\n",
    "thetaFinal = sp.fmin_cg(testFunction, x0=initialTheta, fprime=testFunctionTwo)\n",
    "print(thetaFinal)\n",
    "\n",
    "testCase = np.array([[1, 45, 85]])\n",
    "prob = sigmoid (np.dot(testCase, thetaFinal))\n",
    "print(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros) [ 0.69314718]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.264670\n",
      "         Iterations: 2503\n",
      "         Function evaluations: 9309\n",
      "         Gradient evaluations: 9309\n",
      "[   6.11143429    3.32742323    4.11723508  -53.54083332  -18.38752956\n",
      "  -11.9209605   -30.5651674     3.32847283   22.4259891    -3.00823264\n",
      "  188.93140246   84.95511846  132.0497666    25.95393234   -0.254657\n",
      "   66.5582181    19.36075176   -2.45620279  -14.21227477   -2.37340207\n",
      "   28.05388751 -229.35640972 -154.53550306 -177.88889949  -11.70852868\n",
      " -187.34769795  -93.94977533  -30.43981513]\n"
     ]
    }
   ],
   "source": [
    "# Ex2Data2\n",
    "\n",
    "data = np.loadtxt('/Users/Zohair/Library/Mobile Documents/com~apple~CloudDocs/Education/Machine Learning/machine-learning-ex2/ex2/ex2data2.txt', delimiter = \",\")\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "(m, n) = np.shape(data)\n",
    "\n",
    "# Add Column Of Ones\n",
    "temp = np.ones((m, 1)) \n",
    "data = np.hstack((temp, data))\n",
    "\n",
    "(m, n) = np.shape(data)\n",
    "\n",
    "# Get X and y from data\n",
    "(X, y) = np.hsplit(data, (n - 1,))\n",
    "y = y.flatten()\n",
    "\n",
    "# Feature Mapping\n",
    "mappedX = mapFeature(X[:,1],X[:,2])\n",
    "\n",
    "#Divide the sample into two: ones with positive classification, one with null classification\n",
    "pos = np.array([X[i] for i in range(np.shape(X)[0]) if y[i] == 1])\n",
    "neg = np.array([X[i] for i in range(np.shape(X)[0]) if y[i] == 0])\n",
    "\n",
    "# Plot Data\n",
    "# plotData()\n",
    "\n",
    "# Initialise Theta\n",
    "initialTheta = np.zeros((mappedX.shape[1],1))\n",
    "\n",
    "# Paramaters\n",
    "\n",
    "lmbda = 0\n",
    "\n",
    "# Initial Cost And Gradient\n",
    "cost = computeCost(initialTheta, mappedX, y, lmbda)\n",
    "grad = computeGradient(mappedX, y, initialTheta, lmbda)\n",
    "\n",
    "print (\"Cost at initial theta (zeros)\", cost)\n",
    "\n",
    "\n",
    "def testFunction(theta):\n",
    "     return computeCost(theta, mappedX, y, lmbda)\n",
    "\n",
    "def testFunctionTwo(theta):\n",
    "    return computeGradient(mappedX, y, theta, lmbda)\n",
    "\n",
    "# Minimise Cost\n",
    "\n",
    "thetaFinal = sp.fmin_cg(testFunction, x0=initialTheta, fprime=testFunctionTwo)\n",
    "print(thetaFinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
